{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "parent_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_folder)\n",
    "\n",
    "import main\n",
    "from data.seed_iv import FeatureMethod, Subject, Session\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "config_file = main.parse_opt(['-c', '../local_template.json'])\n",
    "data = main.parse_config(config_file)\n",
    "config = main.Config(data)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess to get \n",
    "    x: all trail samples of one subject\n",
    "    y: all labels of one subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "source": [
    "import scipy.io\n",
    "\n",
    "eeg_raw_data_path = os.path.join(\n",
    "    config.dataset['root_path'],\n",
    "    config.dataset['eeg_raw_data_path']\n",
    ")\n",
    "\n",
    "target_file = os.path.join(eeg_raw_data_path, '1', '1_20160518.mat')\n",
    "data = scipy.io.loadmat(target_file)\n",
    "data.pop('__header__', None)\n",
    "data.pop('__version__', None)\n",
    "data.pop('__globals__', None)\n",
    "\n",
    "data = list(data.values())\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "eeg_feature_data_path = os.path.join(\n",
    "    config.dataset['root_path'],\n",
    "    config.dataset['eeg_feature_smooth_path']\n",
    ")\n",
    "\n",
    "target_feature_file = os.path.join(eeg_feature_data_path, '1', '1_20160518.mat')\n",
    "feature_data = scipy.io.loadmat(target_feature_file)\n",
    "\n",
    "feature_data.pop('__header__', None)\n",
    "feature_data.pop('__version__', None)\n",
    "feature_data.pop('__globals__', None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "de_ma_1 = feature_data['psd_movingAve1']\n",
    "de_ma_1 = np.array(de_ma_1)\n",
    "unshaped = de_ma_1\n",
    "# Frequency band and channel labels\n",
    "freq_bands = ['delta', 'theta', 'alpha', 'beta', 'gamma']\n",
    "channel_labels = [f'ch_{i+1}' for i in range(62)]\n",
    "\n",
    "# Reshape data into a DataFrame\n",
    "reshaped_data = []\n",
    "for i, band in enumerate(freq_bands):\n",
    "    for j, channel in enumerate(channel_labels):\n",
    "        for t in range(unshaped.shape[1]):\n",
    "            reshaped_data.append([unshaped[j, t, i], band, channel, t])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(reshaped_data, columns=['EEG_value', 'Frequency_band', 'Channel', 'Time'])\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define the ANOVA model\n",
    "model = ols('EEG_value ~ C(Frequency_band) + C(Channel) + C(Frequency_band):C(Channel)', data=df).fit()\n",
    "\n",
    "# Perform ANOVA\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "data = np.transpose(unshaped, (2, 0, 1)) # (62, 42, 5)\n",
    "# Example 3D EEG data: (frequency bands, channels, time points)\n",
    "# data = np.random.rand(5, 62, 1000)  # Simulated data for illustration\n",
    "\n",
    "# Step 1: Average over channels and time points\n",
    "# This reduces the data to a 1D array of averages per frequency band\n",
    "data_avg = data.mean(axis=(1, 2))  # Shape: (5,)\n",
    "\n",
    "# Step 2: Organize data by frequency bands for ANOVA\n",
    "# If we were to perform ANOVA directly, we need data arrays per group (frequency band)\n",
    "freq_band_data = [data[i].flatten() for i in range(5)]\n",
    "\n",
    "# Step 3: Perform one-way ANOVA across frequency bands\n",
    "anova_result = f_oneway(*freq_band_data)\n",
    "    \n",
    "# Output the ANOVA result\n",
    "print(\"ANOVA result:\", anova_result)\n",
    "print(\"F-statistic:\", anova_result.statistic)\n",
    "print(\"p-value:\", anova_result.pvalue)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example data setup\n",
    "# data: [samples, features], e.g., each row is a sample's EEG feature vector\n",
    "# labels: Emotion labels corresponding to each sample, e.g., [0, 1, 2, 3]\n",
    "\n",
    "# Example data generation\n",
    "num_samples = 100  # Total number of samples\n",
    "num_features = 5   # Number of EEG features per sample\n",
    "data = np.random.rand(num_samples, num_features)  # Random data for illustration\n",
    "labels = np.random.randint(0, 4, num_samples)  # Random labels 0 to 3 for illustration\n",
    "\n",
    "# Step 1: Organize data by emotion labels\n",
    "emotion_groups = [data[labels == i] for i in range(4)]  # Creates 4 groups based on labels\n",
    "\n",
    "# Step 2: Perform ANOVA on each feature across emotion groups\n",
    "anova_results = []\n",
    "for feature_idx in range(num_features):\n",
    "    # Extract the feature column across all groups\n",
    "    feature_data = [group[:, feature_idx] for group in emotion_groups]\n",
    "    \n",
    "    # Perform ANOVA across the four emotion groups\n",
    "    anova_result = f_oneway(*feature_data)\n",
    "    anova_results.append((feature_idx, anova_result.statistic, anova_result.pvalue))\n",
    "\n",
    "# Output the ANOVA results\n",
    "for feature_idx, f_stat, p_value in anova_results:\n",
    "    print(f\"Feature {feature_idx}: F-statistic = {f_stat}, p-value = {p_value}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set figure format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set font properties globally for consistent appearance\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,        # General font size\n",
    "    'font.family': 'serif', # Use a serif font (e.g., Times New Roman)\n",
    "    'axes.titlesize': 14,   # Title font size\n",
    "    'axes.labelsize': 12,   # Label font size\n",
    "    'xtick.labelsize': 10,  # X-axis tick labels\n",
    "    'ytick.labelsize': 10,  # Y-axis tick labels\n",
    "})"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overrall F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "import pre.conformer \n",
    "import os\n",
    "\n",
    "eeg_feature_data_path = os.path.join(\n",
    "    config.dataset['root_path'],\n",
    "    config.dataset['eeg_feature_smooth_path']\n",
    ")\n",
    "\n",
    "sub_list = [subj for subj in Subject]\n",
    "\n",
    "data_feat, label = pre.conformer.get_feature_dataset(eeg_feature_data_path, \n",
    "                                                            sub_list, \n",
    "                                                            sessions = [Session.ONE, Session.TWO, Session.THREE], \n",
    "                                                            trails=list(range(0, 24)), \n",
    "                                                            method= FeatureMethod.DE_LDS, \n",
    "                                                            block_size=10)\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "# Step 1: Average data over time samples and channels\n",
    "# Shape after mean: (570, 5) - 570 chunks, 5 frequency bands\n",
    "data_mean = data_feat.mean(axis=(1, 2))\n",
    "# Step 2: Separate data into groups by emotion labels\n",
    "emotion_groups = [data_mean[label == i] for i in range(4)]\n",
    "\n",
    "# Step 3: Perform ANOVA (F-test) for each frequency band\n",
    "results = {}\n",
    "for band in range(5):  # Loop over frequency bands\n",
    "    # Extract data for this frequency band across all emotion groups\n",
    "    band_data = [group[:, band] for group in emotion_groups]\n",
    "    # Perform one-way ANOVA\n",
    "    f_stat, p_value = f_oneway(*band_data)\n",
    "    results[f\"Frequency Band {band + 1}\"] = {\"F-statistic\": f_stat, \"p-value\": p_value}\n",
    "\n",
    "# Step 4: Display results\n",
    "for band, stats in results.items():\n",
    "    print(f\"{band}: F-statistic = {stats['F-statistic']:.4f}, p-value = {stats['p-value']:.4e}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 5: Extract results for visualization\n",
    "bands = list(results.keys())\n",
    "f_stats = [stats[\"F-statistic\"] for stats in results.values()]\n",
    "p_values = [stats[\"p-value\"] for stats in results.values()]\n",
    "\n",
    "# Step 6: Create the bar plot for F-statistics\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(bands, f_stats, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Annotate the bars with p-values\n",
    "for bar, p_value in zip(bars, p_values):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "            f\"p={p_value:.2e}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.xlabel(\"Frequency Bands\", fontsize=12)\n",
    "plt.ylabel(\"F-statistic\", fontsize=12)\n",
    "plt.title(\"ANOVA Results Across Frequency Bands of DE_LDS\", fontsize=14)\n",
    "plt.axhline(y=0, color='black', linewidth=0.8, linestyle='--')  # Reference line\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Step 1: Average over time samples and channels\n",
    "data_mean = data_feat.mean(axis=(1, 2))  # Shape: (570, 5)\n",
    "\n",
    "# Step 2: Group data by emotion labels\n",
    "emotion_groups = [data_mean[label == i] for i in range(4)]\n",
    "\n",
    "# Step 3: Perform F-test for each frequency band\n",
    "results = {}\n",
    "for band in range(5):  # Loop over frequency bands\n",
    "    # Extract data for this frequency band across all emotion groups\n",
    "    band_data = [group[:, band] for group in emotion_groups]\n",
    "    # Perform one-way ANOVA\n",
    "    f_stat, p_value = f_oneway(*band_data)\n",
    "    results[f\"Frequency Band {band + 1}\"] = {\"F-statistic\": f_stat, \"p-value\": p_value}\n",
    "\n",
    "# Step 4: Visualize results for each band\n",
    "plt.figure(figsize=(14, 8))\n",
    "for band in range(5):\n",
    "    # Extract data for this band\n",
    "    band_data = [group[:, band] for group in emotion_groups]\n",
    "    \n",
    "    # Create subplot for each band\n",
    "    plt.subplot(2, 3, band + 1)\n",
    "    plt.boxplot(band_data, tick_labels=[\"Emotion 0\", \"Emotion 1\", \"Emotion 2\", \"Emotion 3\"], patch_artist=True)\n",
    "    \n",
    "    # Add F-statistic and p-value as the title\n",
    "    f_stat = results[f\"Frequency Band {band + 1}\"][\"F-statistic\"]\n",
    "    p_value = results[f\"Frequency Band {band + 1}\"][\"p-value\"]\n",
    "    plt.title(f\"Freq Band {band + 1}\\nF-stat: {f_stat:.2f}, p: {p_value:.2e}\")\n",
    "    \n",
    "    # Add labels\n",
    "    plt.xlabel(\"Emotion Labels\")\n",
    "    plt.ylabel(\"Mean Value\")\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"F-Test Results Across Frequency Bands of DE_LDS\", fontsize=16, y=1.02)\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pre.conformer \n",
    "import os\n",
    "\n",
    "eeg_feature_data_path = os.path.join(\n",
    "    config.dataset['root_path'],\n",
    "    config.dataset['eeg_feature_smooth_path']\n",
    ")\n",
    "\n",
    "for subj in Subject:\n",
    "    sub_list = [subj]\n",
    "\n",
    "    data_feat, label = pre.conformer.get_feature_dataset(eeg_feature_data_path, \n",
    "                                                                sub_list, \n",
    "                                                                sessions = [Session.ONE, Session.TWO, Session.THREE], \n",
    "                                                                trails=list(range(0, 24)), \n",
    "                                                                method= FeatureMethod.DE_LDS, \n",
    "                                                                sample_length=10)\n",
    "    from scipy.stats import f_oneway\n",
    "    # Step 1: Average data over time samples and channels\n",
    "    # Shape after mean: (570, 5) - 570 chunks, 5 frequency bands\n",
    "    data_mean = data_feat.mean(axis=(1, 2))\n",
    "    # Step 2: Separate data into groups by emotion labels\n",
    "    emotion_groups = [data_mean[label == i] for i in range(4)]\n",
    "\n",
    "    # Step 3: Perform ANOVA (F-test) for each frequency band\n",
    "    results = {}\n",
    "    for band in range(5):  # Loop over frequency bands\n",
    "        # Extract data for this frequency band across all emotion groups\n",
    "        band_data = [group[:, band] for group in emotion_groups]\n",
    "        # Perform one-way ANOVA\n",
    "        f_stat, p_value = f_oneway(*band_data)\n",
    "        results[f\"Frequency Band {band + 1}\"] = {\"F-statistic\": f_stat, \"p-value\": p_value}\n",
    "\n",
    "    # Step 4: Display results\n",
    "    for band, stats in results.items():\n",
    "        print(f\"{band}: F-statistic = {stats['F-statistic']:.4f}, p-value = {stats['p-value']:.4e}\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Step 5: Extract results for visualization\n",
    "    bands = list(results.keys())\n",
    "    f_stats = [stats[\"F-statistic\"] for stats in results.values()]\n",
    "    p_values = [stats[\"p-value\"] for stats in results.values()]\n",
    "\n",
    "    # Step 6: Create the bar plot for F-statistics\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(bands, f_stats, color='skyblue', edgecolor='black')\n",
    "\n",
    "    # Annotate the bars with p-values\n",
    "    for bar, p_value in zip(bars, p_values):\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), \n",
    "                f\"p={p_value:.2e}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "    # Add labels, title, and grid\n",
    "    plt.xlabel(\"Frequency Bands\", fontsize=12)\n",
    "    plt.ylabel(\"F-statistic\", fontsize=12)\n",
    "    plt.title(f\"ANOVA Results Across Frequency Bands of Subject {sub_list[0].value}\", fontsize=14)\n",
    "    plt.axhline(y=0, color='black', linewidth=0.8, linestyle='--')  # Reference line\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "    # Step 1: Average over time samples and channels\n",
    "    data_mean = data_feat.mean(axis=(1, 2))  # Shape: (570, 5)\n",
    "\n",
    "    # Step 2: Group data by emotion labels\n",
    "    emotion_groups = [data_mean[label == i] for i in range(4)]\n",
    "\n",
    "    # Step 3: Perform F-test for each frequency band\n",
    "    results = {}\n",
    "    for band in range(5):  # Loop over frequency bands\n",
    "        # Extract data for this frequency band across all emotion groups\n",
    "        band_data = [group[:, band] for group in emotion_groups]\n",
    "        # Perform one-way ANOVA\n",
    "        f_stat, p_value = f_oneway(*band_data)\n",
    "        results[f\"Frequency Band {band + 1}\"] = {\"F-statistic\": f_stat, \"p-value\": p_value}\n",
    "\n",
    "    # Step 4: Visualize results for each band\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for band in range(5):\n",
    "        # Extract data for this band\n",
    "        band_data = [group[:, band] for group in emotion_groups]\n",
    "        \n",
    "        # Create subplot for each band\n",
    "        plt.subplot(2, 3, band + 1)\n",
    "        plt.boxplot(band_data, tick_labels=[\"Emotion 0\", \"Emotion 1\", \"Emotion 2\", \"Emotion 3\"], patch_artist=True)\n",
    "        \n",
    "        # Add F-statistic and p-value as the title\n",
    "        f_stat = results[f\"Frequency Band {band + 1}\"][\"F-statistic\"]\n",
    "        p_value = results[f\"Frequency Band {band + 1}\"][\"p-value\"]\n",
    "        plt.title(f\"Freq Band {band + 1}\\nF-stat: {f_stat:.2f}, p: {p_value:.2e}\")\n",
    "        \n",
    "        # Add labels\n",
    "        plt.xlabel(\"Emotion Labels\")\n",
    "        plt.ylabel(\"Mean Value\")\n",
    "\n",
    "    # Adjust layout and show plot\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"F-Test Results Across Frequency Bands of Subject {sub_list[0].value}\", fontsize=16, y=1.02)\n",
    "    plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your EEG data is stored in a 2D NumPy array called 'eeg_data'\n",
    "# with shape (62, 30000) representing 62 channels and 30000 time samples\n",
    "\n",
    "# Convert the EEG data to a Pandas DataFrame\n",
    "eeg_df = pd.DataFrame(data[1].T)  # Transpose to have channels as columns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = eeg_df.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(12, 10))  # Adjust figure size as needed\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='viridis', center=0)\n",
    "plt.title('EEG Channel Correlation Heatmap')\n",
    "plt.xlabel('EEG Channels')\n",
    "plt.ylabel('EEG Channels')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming you have 'eeg_data' (62, 30000) and 'emotion_labels' (30000)\n",
    "\n",
    "# Choose a specific channel to compare (e.g., channel 1)\n",
    "channel_to_compare = 0\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "data = {'Amplitude': eeg_data[channel_to_compare, :], 'Emotion': emotion_labels}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot box plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='Emotion', y='Amplitude', data=df)\n",
    "plt.title(f'EEG Amplitude Distribution for Channel {channel_to_compare + 1}')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# 1. Visualize class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "unique_labels, counts = np.unique(y, return_counts=True)\n",
    "plt.bar(unique_labels, counts)\n",
    "plt.title('Distribution of Classes')\n",
    "plt.xlabel('Class Label')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 2. Visualize feature patterns\n",
    "# Plot first sample's features across channels and time\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(x[0, 0], cmap='viridis')\n",
    "plt.title('Feature Heatmap (First Sample)')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Channels')\n",
    "plt.show()\n",
    "\n",
    "# 3. Feature distribution across all samples\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([x[:, :, i].flatten() for i in range(x.shape[2])])\n",
    "plt.title('Feature Distribution by Channel')\n",
    "plt.xlabel('Feature Channel')\n",
    "plt.ylabel('Value')\n",
    "plt.show()\n",
    "\n",
    "# Print shape information\n",
    "print(f\"X shape: {x.shape}\")  # Should be (n_samples, n_channels, n_features)\n",
    "print(f\"Y shape: {y.shape}\")  # Should be (n_samples,)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Original shape: (285, 5, 10, 62)\n",
    "# 285: time samples/block_size\n",
    "# 5: frequency bands\n",
    "# 10: block size\n",
    "# 62: electrodes\n",
    "\n",
    "# 1. Reshape the 4D data to 2D for PCA\n",
    "\n",
    "\n",
    "X_reshaped = x.reshape(x.shape[0], -1)  # Shape will be (285, 5*10*62 = 3100)\n",
    "\n",
    "# 2. Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "\n",
    "# 3. Apply PCA\n",
    "pca = PCA()  # no n_components means keep all components\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# 4. Visualize explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Explained Variance Ratio vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 5. Print explained variance ratio\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# 6. Select number of components (e.g., 95% variance explained)\n",
    "n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
    "print(f\"Number of components needed for 95% variance: {n_components}\")\n",
    "\n",
    "# 7. Apply PCA with selected components\n",
    "pca_final = PCA(n_components=n_components)\n",
    "X_pca_final = pca_final.fit_transform(X_scaled)\n",
    "\n",
    "# 8. Visualize first two components (if you want to see the distribution)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X_pca_final[:, 0], X_pca_final[:, 1], c=y, cmap='viridis')\n",
    "plt.xlabel('First Principal Component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title('First Two Principal Components')\n",
    "plt.colorbar(label='Class')\n",
    "plt.show()\n",
    "\n",
    "print(f\"X_pca_final shape: {X_pca_final.shape}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "from model.conformer_feature import ConformerFeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add lists to store metrics\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Create figure for plotting\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    x_train_tensor = torch.from_numpy(np.array(x_train)).float()\n",
    "    y_train_tensor = torch.from_numpy(np.array(y_train)).long()\n",
    "    x_test_tensor = torch.from_numpy(np.array(x_test)).float()\n",
    "    y_test_tensor = torch.from_numpy(np.array(y_test)).long()\n",
    "\n",
    "    train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    model = ConformerFeature(channels=5, block_size=10)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
    "\n",
    "    # Initialize fold-specific metric lists\n",
    "    fold_train_acc = []\n",
    "    fold_test_acc = []\n",
    "    fold_train_loss = []\n",
    "    fold_test_loss = []\n",
    "\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "\n",
    "        print(f'Epoch: {epoch} ----------------------------')\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(batch_x)\n",
    "\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_predictions += predicted.eq(batch_y).sum().item()\n",
    "            total_samples += batch_y.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct_predictions / total_samples\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                y_pred = model(batch_x)\n",
    "                loss = criterion(y_pred, batch_y)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(y_pred, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += predicted.eq(batch_y).sum().item()\n",
    "\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "        test_accuracy = correct / total\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "        \n",
    "        # Store metrics\n",
    "        fold_train_acc.append(epoch_accuracy)\n",
    "        fold_train_loss.append(epoch_loss)\n",
    "        fold_test_acc.append(test_accuracy)\n",
    "        fold_test_loss.append(test_loss)\n",
    "\n",
    "    # After training, store fold metrics\n",
    "    train_accuracies.append(fold_train_acc)\n",
    "    test_accuracies.append(fold_test_acc)\n",
    "    train_losses.append(fold_train_loss)\n",
    "    test_losses.append(fold_test_loss)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"k-fold end\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracies\n",
    "plt.subplot(1, 2, 1)\n",
    "for fold in range(len(train_accuracies)):\n",
    "    plt.plot(train_accuracies[fold], label=f'Train Fold {fold+1}', alpha=0.3)\n",
    "    plt.plot(test_accuracies[fold], label=f'Test Fold {fold+1}', alpha=0.3)\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot losses\n",
    "plt.subplot(1, 2, 2)\n",
    "for fold in range(len(train_losses)):\n",
    "    plt.plot(train_losses[fold], label=f'Train Fold {fold+1}', alpha=0.3)\n",
    "    plt.plot(test_losses[fold], label=f'Test Fold {fold+1}', alpha=0.3)\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
